# Aliconcon MCP Client - OpenRouter + AI Models

Trá»£ lÃ½ AI thÃ´ng minh cho ná»n táº£ng thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ Aliconcon, sá»­ dá»¥ng cÃ¡c AI models MIá»„N PHÃ qua OpenRouter vá»›i MCP (Model Context Protocol).

## ğŸš€ TÃ­nh nÄƒng

-   **MIá»„N PHÃ**: Sá»­ dá»¥ng Qwen3 30B vÃ  cÃ¡c models khÃ¡c hoÃ n toÃ n miá»…n phÃ­ qua OpenRouter
-   **MCP Integration**: Káº¿t ná»‘i vá»›i MCP server Ä‘á»ƒ truy cáº­p tools vÃ  resources
-   **Tool Calling**: AI cÃ³ thá»ƒ gá»i cÃ¡c tools Ä‘á»ƒ láº¥y thÃ´ng tin thá»±c táº¿ (vá»›i models há»— trá»£)
-   **Fallback System**: Tá»± Ä‘á»™ng chuyá»ƒn sang cháº¿ Ä‘á»™ fallback náº¿u model khÃ´ng há»— trá»£ tools
-   **Multi-Model Support**: Há»— trá»£ hÆ¡n 300 AI models qua OpenRouter

## ğŸ”§ CÃ i Ä‘áº·t

### 1. Láº¥y API Key MIá»„N PHÃ tá»« OpenRouter

1. Truy cáº­p [https://openrouter.ai](https://openrouter.ai)
2. ÄÄƒng kÃ½ tÃ i khoáº£n MIá»„N PHÃ
3. VÃ o Dashboard â†’ Keys â†’ Create Key
4. Copy API key

### 2. Cáº¥u hÃ¬nh Environment

```bash
# Äáº·t API key (REQUIRED)
export OPENROUTER_API_KEY='your_api_key_here'

# Cáº¥u hÃ¬nh tÃ¹y chá»n
export LLM_MODEL='qwen/qwen3-30b-a3b:free'  # Model máº·c Ä‘á»‹nh (MIá»„N PHÃ)
export LLM_TEMPERATURE='0.7'
export DISABLE_THINKING='true'
export MCP_PORT='8000'
export MCP_URL='http://localhost:8000'
```

### 3. CÃ i Ä‘áº·t dependencies

```bash
cd client-mcp
bun install
```

## ğŸ¯ Sá»­ dá»¥ng

### Cháº¡y tá»« script tá»± Ä‘á»™ng (Khuyáº¿n nghá»‹)

```bash
# Tá»« thÆ° má»¥c gá»‘c dá»± Ã¡n
./run_aliconcon_mcp.sh
```

### Cháº¡y thá»§ cÃ´ng

```bash
# Terminal 1: Start MCP server
cd server-mcp
bun run server.ts

# Terminal 2: Start client
cd client-mcp
export OPENROUTER_API_KEY='your_api_key_here'
bun run index.ts
```

## ğŸ¤– Models Ä‘Æ°á»£c khuyáº¿n nghá»‹

### Models MIá»„N PHÃ há»— trá»£ Tool Calling:

```bash
export LLM_MODEL='qwen/qwen3-30b-a3b:free'        # Qwen3 30B (Khuyáº¿n nghá»‹)
export LLM_MODEL='meta-llama/llama-4-maverick:free' # Llama 4 Maverick
export LLM_MODEL='google/gemini-2.5-pro:free'     # Gemini 2.5 Pro
```

### Models MIá»„N PHÃ khÃ´ng há»— trá»£ Tool Calling (sá»­ dá»¥ng fallback):

```bash
export LLM_MODEL='deepseek/deepseek-r1:free'      # DeepSeek R1
export LLM_MODEL='mistral/mistral-small-3.1:free' # Mistral Small 3.1
```

### Models CÃ“ PHÃ vá»›i Tool Calling máº¡nh:

```bash
export LLM_MODEL='openai/gpt-4o'                  # GPT-4o
export LLM_MODEL='anthropic/claude-3.5-sonnet'    # Claude 3.5 Sonnet
export LLM_MODEL='google/gemini-2.5-pro'          # Gemini 2.5 Pro (paid)
```

## âš ï¸ Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p

### Lá»—i 401 - No auth credentials found

```
âŒ Error: 401 No auth credentials found
```

**NguyÃªn nhÃ¢n**: API key khÃ´ng Ä‘Æ°á»£c Ä‘áº·t hoáº·c khÃ´ng há»£p lá»‡

**Giáº£i phÃ¡p**:

1. Kiá»ƒm tra API key Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº·t: `echo $OPENROUTER_API_KEY`
2. Náº¿u chÆ°a cÃ³, Ä‘áº·t API key: `export OPENROUTER_API_KEY='your_key'`
3. Náº¿u Ä‘Ã£ cÃ³, kiá»ƒm tra key cÃ³ Ä‘Ãºng khÃ´ng táº¡i [https://openrouter.ai/keys](https://openrouter.ai/keys)
4. Táº¡o key má»›i náº¿u cáº§n thiáº¿t

### Lá»—i 404 - No endpoints found that support tool use

```
âŒ Error: 404 No endpoints found that support tool use
```

**NguyÃªn nhÃ¢n**: Model hiá»‡n táº¡i khÃ´ng há»— trá»£ tool calling

**Giáº£i phÃ¡p**: Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng chuyá»ƒn sang cháº¿ Ä‘á»™ fallback, hoáº·c báº¡n cÃ³ thá»ƒ thay Ä‘á»•i model:

```bash
export LLM_MODEL='qwen/qwen3-30b-a3b:free'  # Model miá»…n phÃ­ há»— trá»£ tools
```

### Lá»—i "No endpoints found for model"

**NguyÃªn nhÃ¢n**: Model khÃ´ng tá»“n táº¡i hoáº·c khÃ´ng kháº£ dá»¥ng

**Giáº£i phÃ¡p**: Kiá»ƒm tra danh sÃ¡ch models kháº£ dá»¥ng táº¡i [https://openrouter.ai/models](https://openrouter.ai/models)

## ğŸ› ï¸ Available Tools

-   `introduce`: Giá»›i thiá»‡u vá» ná»n táº£ng Aliconcon
-   `popular-products`: Láº¥y danh sÃ¡ch sáº£n pháº©m phá»• biáº¿n

## ğŸ”„ Cháº¿ Ä‘á»™ Fallback

Khi model khÃ´ng há»— trá»£ tool calling, há»‡ thá»‘ng tá»± Ä‘á»™ng chuyá»ƒn sang cháº¿ Ä‘á»™ fallback vá»›i:

-   Context-aware prompting vá»›i thÃ´ng tin vá» Aliconcon
-   Static responses cho cÃ¡c cÃ¢u há»i phá»• biáº¿n
-   Váº«n cung cáº¥p tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng tá»‘t

## ğŸ“– Tham kháº£o

-   [OpenRouter Documentation](https://openrouter.ai/docs)
-   [OpenRouter Models](https://openrouter.ai/models)
-   [OpenRouter Tool Calling Guide](https://openrouter.ai/docs/features/tool-calling)

## ğŸ”„ Cáº¥u hÃ¬nh nÃ¢ng cao

### Báº­t Thinking Traces (cho models há»— trá»£)

```bash
export DISABLE_THINKING='false'
```

### Sá»­ dá»¥ng Model Routing

```bash
# Æ¯u tiÃªn tá»‘c Ä‘á»™
export LLM_MODEL='qwen/qwen3-30b-a3b:nitro'

# Æ¯u tiÃªn giÃ¡ ráº»
export LLM_MODEL='qwen/qwen3-30b-a3b:floor'
```

### Thay Ä‘á»•i Temperature

```bash
export LLM_TEMPERATURE='0.3'  # Conservative
export LLM_TEMPERATURE='0.9'  # Creative
```

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
client-mcp/
â”œâ”€â”€ index.ts           # Main client application
â”œâ”€â”€ package.json       # Dependencies vÃ  scripts
â”œâ”€â”€ tsconfig.json      # TypeScript configuration
â”œâ”€â”€ README.md          # Documentation
â””â”€â”€ .gitignore         # Git ignore rules
```

## ğŸ”— LiÃªn quan

-   [Aliconcon MCP Server](../server-mcp/README.md)
-   [Ollama Documentation](https://ollama.ai/docs)
-   [Model Context Protocol](https://modelcontextprotocol.io/)

---

**Aliconcon MCP Client** - Tráº£i nghiá»‡m AI shopping thÃ´ng minh! ğŸ›ï¸ğŸ¤–
