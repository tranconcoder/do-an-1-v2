import { stdin as input, stdout as output } from "node:process";
import * as readline from "node:readline/promises";
import OpenAI from "openai";
import { config } from "dotenv";
import pino from "pino";
import pretty from "pino-pretty";

// Load environment variables
config();

// Configure logger
const logger = pino(pretty({ colorize: true }));

// Configuration
const OPENROUTER_API_KEY = "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";
// const MODEL_NAME = process.env.LLM_MODEL || "meta-llama/llama-3-70b-instruct";
const MODEL_NAME = process.env.LLM_MODEL || "deepseek/deepseek-chat-v3-0324:free";
const DISABLE_THINKING = process.env.DISABLE_THINKING === "true" || true;
const MCP_SERVER_URL = process.env.MCP_URL || "http://localhost:8000";

// OpenAI client configured for OpenRouter
const openai = new OpenAI({
    apiKey: OPENROUTER_API_KEY,
    baseURL: "https://openrouter.ai/api/v1",
});

// Helper function to convert MCP tool definitions to OpenAI format
function convertToolFormat(tool: any): any {
    return {
        type: "function",
        function: {
            name: tool.name,
            description: tool.description,
            parameters: {
                type: "object",
                properties: tool.inputSchema?.properties || {},
                required: tool.inputSchema?.required || []
            }
        }
    };
}

class AliconconMCPClient {
    private messages: any[] = [];
    private rl: readline.Interface;
    private availableTools: any[] = [];

    constructor() {
        this.rl = readline.createInterface({ input, output });
    }

    async connectToServer(): Promise<boolean> {
        try {
            logger.info("üîó Connecting to Aliconcon MCP Server...");

            // Test MCP server connection
            const healthResponse = await fetch(`${MCP_SERVER_URL}/health`);
            if (!healthResponse.ok) {
                throw new Error(`Health check failed: ${healthResponse.status}`);
            }

            // Get available tools
            const toolsResponse = await fetch(`${MCP_SERVER_URL}/tools`);
            if (!toolsResponse.ok) {
                throw new Error(`Tools fetch failed: ${toolsResponse.status}`);
            }

            const toolsData = await toolsResponse.json() as any;
            this.availableTools = toolsData.result?.tools || [];

            logger.info("‚úÖ Connected to MCP server with tools:", this.availableTools.map((tool: any) => tool.name));

            return true;
        } catch (error) {
            logger.error("‚ùå Failed to connect to MCP server:", error);
            return false;
        }
    }

    async callMCPTool(toolName: string, toolArgs: any): Promise<string> {
        try {
            const response = await fetch(`${MCP_SERVER_URL}/tools/call`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    name: toolName,
                    arguments: toolArgs
                })
            });

            if (!response.ok) {
                throw new Error(`Tool call failed: ${response.status}`);
            }

            const result = await response.json() as any;

            // Extract content from MCP response
            if (result.result?.content) {
                if (Array.isArray(result.result.content)) {
                    return result.result.content.map((c: any) => c.text || JSON.stringify(c)).join('\n');
                } else {
                    return result.result.content;
                }
            }

            return JSON.stringify(result.result, null, 2);
        } catch (error) {
            logger.error(`‚ùå Error calling tool ${toolName}:`, error);
            throw error;
        }
    }

    async processQuery(query: string): Promise<string> {
        // Add user message
        this.messages.push({
            role: "user",
            content: query
        });

        try {
            // Convert tools to OpenAI format
            const availableTools = this.availableTools.map(convertToolFormat);

            logger.info(`üõ†Ô∏è Available tools: ${this.availableTools.map((t: any) => t.name).join(', ')}`);

            // First, try with tools if available
            let useTools = availableTools.length > 0;

            try {
                // Call OpenRouter with tools
                const response = await openai.chat.completions.create({
                    model: MODEL_NAME,
                    messages: this.messages,
                    tools: useTools ? availableTools : undefined,
                    temperature: 0.7,
                    max_tokens: 2048
                });

                const message = response.choices[0]?.message;
                if (!message) {
                    throw new Error("No message received from OpenRouter");
                }

                this.messages.push({
                    role: message.role,
                    content: message.content,
                    tool_calls: message.tool_calls
                });

                let finalText: string[] = [];

                // Handle tool calls if any
                if (message.tool_calls && message.tool_calls.length > 0) {
                    logger.info(`‚úÖ Tool calling supported! Processing ${message.tool_calls.length} tool calls`);

                    for (const toolCall of message.tool_calls) {
                        const toolName = toolCall.function.name;
                        const toolArgs = JSON.parse(toolCall.function.arguments || "{}");

                        logger.info(`üîß Calling tool: ${toolName} with args:`, toolArgs);
                        finalText.push(`[ƒêang g·ªçi tool ${toolName}...]`);

                        try {
                            // Execute tool call via MCP HTTP API
                            const result = await this.callMCPTool(toolName, toolArgs);

                            // Add tool result to messages
                            this.messages.push({
                                role: "tool",
                                tool_call_id: toolCall.id,
                                name: toolName,
                                content: result
                            });

                            logger.info(`‚úÖ Tool ${toolName} executed successfully`);

                        } catch (error) {
                            logger.error(`‚ùå Error calling tool ${toolName}:`, error);
                            this.messages.push({
                                role: "tool",
                                tool_call_id: toolCall.id,
                                name: toolName,
                                content: `Error: ${error}`
                            });
                        }
                    }

                    // Get final response after tool execution
                    const finalResponse = await openai.chat.completions.create({
                        model: MODEL_NAME,
                        messages: this.messages,
                        max_tokens: 1000,
                        temperature: 0.7
                    });

                    const finalMessage = finalResponse.choices[0]?.message;
                    if (!finalMessage) {
                        throw new Error("No final message received from OpenRouter");
                    }

                    this.messages.push({
                        role: finalMessage.role,
                        content: finalMessage.content
                    });

                    finalText.push(finalMessage.content || "");
                } else {
                    // No tool calls, just return the response
                    logger.info("‚ÑπÔ∏è No tool calls made, returning direct response");
                    finalText.push(message.content || "");
                }

                return finalText.join('\n');

            } catch (toolError: any) {
                // If tool calling fails (404 error), fall back to no-tool mode
                if (toolError.message?.includes('404') && toolError.message?.includes('tool use')) {
                    logger.warn("üîÑ Tool calling not supported by this model, falling back to context-aware mode");
                    return await this.processQueryWithoutTools(query);
                }

                // Check for other tool-related errors
                if (toolError.message?.includes('tool') || toolError.message?.includes('function')) {
                    logger.warn("üîÑ Tool-related error detected, falling back to context-aware mode");
                    return await this.processQueryWithoutTools(query);
                }

                throw toolError;
            }

        } catch (error) {
            logger.error("‚ùå Error processing query:", error);
            throw error;
        }
    }

    async processQueryWithoutTools(query: string): Promise<string> {
        try {
            // Create a context-aware prompt that includes information about Aliconcon
            const contextPrompt = `B·∫°n l√† tr·ª£ l√Ω AI c·ªßa Aliconcon - n·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ h√†ng ƒë·∫ßu Vi·ªát Nam.

TH√îNG TIN V·ªÄ ALICONCON:
- Aliconcon l√† n·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ ƒëa d·∫°ng v·ªõi h√†ng tri·ªáu s·∫£n ph·∫©m
- Chuy√™n cung c·∫•p c√°c s·∫£n ph·∫©m: ƒëi·ªán t·ª≠, th·ªùi trang, gia d·ª•ng, s√°ch, ƒë·ªì ch∆°i
- C√≥ h·ªá th·ªëng giao h√†ng nhanh to√†n qu·ªëc
- H·ªó tr·ª£ thanh to√°n ƒëa d·∫°ng: COD, chuy·ªÉn kho·∫£n, v√≠ ƒëi·ªán t·ª≠
- C√≥ ch∆∞∆°ng tr√¨nh khuy·∫øn m√£i v√† t√≠ch ƒëi·ªÉm th∆∞·ªùng xuy√™n
- H·ªó tr·ª£ kh√°ch h√†ng 24/7

S·∫¢N PH·∫®M PH·ªî BI·∫æN:
- iPhone 15 Pro Max - 29.990.000ƒë
- Samsung Galaxy S24 Ultra - 26.990.000ƒë  
- MacBook Air M3 - 28.990.000ƒë
- √Åo thun nam basic - 199.000ƒë
- Gi√†y sneaker n·ªØ - 899.000ƒë
- N·ªìi c∆°m ƒëi·ªán Panasonic - 1.290.000ƒë

H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa kh√°ch h√†ng m·ªôt c√°ch th√¢n thi·ªán v√† h·ªØu √≠ch. N·∫øu ƒë∆∞·ª£c h·ªèi v·ªÅ s·∫£n ph·∫©m c·ª• th·ªÉ m√† kh√¥ng c√≥ trong danh s√°ch, h√£y g·ª£i √Ω c√°c s·∫£n ph·∫©m t∆∞∆°ng t·ª±.

C√¢u h·ªèi c·ªßa kh√°ch h√†ng: ${query}`;

            // Remove the user message we added earlier since we're creating a new context
            this.messages.pop();

            // Add the context-aware message
            this.messages.push({
                role: "user",
                content: contextPrompt
            });

            const response = await openai.chat.completions.create({
                model: MODEL_NAME,
                messages: this.messages,
                temperature: 0.7,
                max_tokens: 1500
            });

            const message = response.choices[0]?.message;
            if (!message) {
                throw new Error("No message received from OpenRouter");
            }

            this.messages.push({
                role: message.role,
                content: message.content
            });

            return message.content || "Xin l·ªói, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω c√¢u h·ªèi n√†y l√∫c n√†y.";

        } catch (error) {
            logger.error("‚ùå Error in fallback mode:", error);

            // Ultimate fallback with static responses
            return this.getStaticResponse(query);
        }
    }

    getStaticResponse(query: string): string {
        const lowerQuery = query.toLowerCase();

        if (lowerQuery.includes('gi·ªõi thi·ªáu') || lowerQuery.includes('aliconcon') || lowerQuery.includes('v·ªÅ')) {
            return `üõçÔ∏è **Ch√†o m·ª´ng ƒë·∫øn v·ªõi Aliconcon!**

Aliconcon l√† n·ªÅn t·∫£ng th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ h√†ng ƒë·∫ßu Vi·ªát Nam v·ªõi:

‚ú® **ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t:**
‚Ä¢ H√†ng tri·ªáu s·∫£n ph·∫©m ƒëa d·∫°ng
‚Ä¢ Giao h√†ng nhanh to√†n qu·ªëc
‚Ä¢ Thanh to√°n an to√†n, ƒëa d·∫°ng
‚Ä¢ H·ªó tr·ª£ kh√°ch h√†ng 24/7
‚Ä¢ Ch∆∞∆°ng tr√¨nh khuy·∫øn m√£i h·∫•p d·∫´n

üõí **Danh m·ª•c s·∫£n ph·∫©m:**
‚Ä¢ ƒêi·ªán t·ª≠ - C√¥ng ngh·ªá
‚Ä¢ Th·ªùi trang Nam/N·ªØ
‚Ä¢ Gia d·ª•ng - N·ªôi th·∫•t
‚Ä¢ S√°ch - VƒÉn ph√≤ng ph·∫©m
‚Ä¢ ƒê·ªì ch∆°i - M·∫π & B√©

üíù **Cam k·∫øt:**
‚Ä¢ S·∫£n ph·∫©m ch√≠nh h√£ng 100%
‚Ä¢ ƒê·ªïi tr·∫£ trong 30 ng√†y
‚Ä¢ B·∫£o h√†nh ch√≠nh h√£ng
‚Ä¢ Gi√° c·∫£ c·∫°nh tranh

B·∫°n c√≥ mu·ªën t√¨m hi·ªÉu v·ªÅ s·∫£n ph·∫©m n√†o c·ª• th·ªÉ kh√¥ng?`;
        }

        if (lowerQuery.includes('s·∫£n ph·∫©m') || lowerQuery.includes('b√°n ch·∫°y') || lowerQuery.includes('ph·ªï bi·∫øn')) {
            return `üî• **S·∫£n ph·∫©m b√°n ch·∫°y t·∫°i Aliconcon:**

üì± **ƒêi·ªán t·ª≠ - C√¥ng ngh·ªá:**
‚Ä¢ iPhone 15 Pro Max - 29.990.000ƒë
‚Ä¢ Samsung Galaxy S24 Ultra - 26.990.000ƒë  
‚Ä¢ MacBook Air M3 - 28.990.000ƒë
‚Ä¢ AirPods Pro 2 - 5.990.000ƒë

üëï **Th·ªùi trang:**
‚Ä¢ √Åo thun nam basic - 199.000ƒë
‚Ä¢ Gi√†y sneaker n·ªØ - 899.000ƒë
‚Ä¢ T√∫i x√°ch n·ªØ da th·∫≠t - 1.299.000ƒë

üè† **Gia d·ª•ng:**
‚Ä¢ N·ªìi c∆°m ƒëi·ªán Panasonic - 1.290.000ƒë
‚Ä¢ M√°y l·ªçc n∆∞·ªõc RO - 3.990.000ƒë
‚Ä¢ Robot h√∫t b·ª•i Xiaomi - 4.590.000ƒë

üí° **G·ª£i √Ω:** T·∫•t c·∫£ s·∫£n ph·∫©m ƒë·ªÅu c√≥ ch∆∞∆°ng tr√¨nh tr·∫£ g√≥p 0% v√† freeship to√†n qu·ªëc!

B·∫°n quan t√¢m ƒë·∫øn danh m·ª•c n√†o?`;
        }

        if (lowerQuery.includes('mua') || lowerQuery.includes('ƒë·∫∑t h√†ng') || lowerQuery.includes('thanh to√°n')) {
            return `üí≥ **H∆∞·ªõng d·∫´n mua h√†ng t·∫°i Aliconcon:**

üõí **C√°c b∆∞·ªõc ƒë·∫∑t h√†ng:**
1. T√¨m ki·∫øm s·∫£n ph·∫©m
2. Ch·ªçn s·∫£n ph·∫©m v√† th√™m v√†o gi·ªè
3. Ki·ªÉm tra gi·ªè h√†ng
4. ƒêi·ªÅn th√¥ng tin giao h√†ng
5. Ch·ªçn ph∆∞∆°ng th·ª©c thanh to√°n
6. X√°c nh·∫≠n ƒë∆°n h√†ng

üí∞ **Ph∆∞∆°ng th·ª©c thanh to√°n:**
‚Ä¢ COD (Thanh to√°n khi nh·∫≠n h√†ng)
‚Ä¢ Chuy·ªÉn kho·∫£n ng√¢n h√†ng
‚Ä¢ V√≠ ƒëi·ªán t·ª≠ (MoMo, ZaloPay)
‚Ä¢ Th·∫ª t√≠n d·ª•ng/ghi n·ª£
‚Ä¢ Tr·∫£ g√≥p 0% (cho ƒë∆°n t·ª´ 3 tri·ªáu)

üöö **Giao h√†ng:**
‚Ä¢ N·ªôi th√†nh: 1-2 ng√†y
‚Ä¢ Ngo·∫°i th√†nh: 2-3 ng√†y
‚Ä¢ Freeship cho ƒë∆°n t·ª´ 150k

B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ th√™m kh√¥ng?`;
        }

        // Default response
        return `ü§ñ **Tr·ª£ l√Ω Aliconcon**

Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:

‚Ä¢ üè™ T√¨m hi·ªÉu v·ªÅ n·ªÅn t·∫£ng Aliconcon
‚Ä¢ üõçÔ∏è Xem s·∫£n ph·∫©m b√°n ch·∫°y v√† khuy·∫øn m√£i
‚Ä¢ üí° H∆∞·ªõng d·∫´n mua h√†ng v√† thanh to√°n
‚Ä¢ üìû H·ªó tr·ª£ d·ªãch v·ª• kh√°ch h√†ng

Vui l√≤ng cho t√¥i bi·∫øt b·∫°n c·∫ßn h·ªó tr·ª£ g√¨ c·ª• th·ªÉ!

*L∆∞u √Ω: Do s·ª≠ d·ª•ng model mi·ªÖn ph√≠, m·ªôt s·ªë t√≠nh nƒÉng n√¢ng cao c√≥ th·ªÉ b·ªã h·∫°n ch·∫ø.*`;
    }

    async startChatLoop() {
        console.log("\nüõçÔ∏è Tr·ª£ l√Ω AI Aliconcon - N·ªÅn t·∫£ng Th∆∞∆°ng m·∫°i ƒêi·ªán t·ª≠ üõçÔ∏è");
        console.log("-".repeat(60));
        console.log("Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi Aliconcon! T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:");
        console.log("  ‚Ä¢ T√¨m hi·ªÉu v·ªÅ n·ªÅn t·∫£ng Aliconcon");
        console.log("  ‚Ä¢ Xem s·∫£n ph·∫©m ph·ªï bi·∫øn v√† b√°n ch·∫°y");
        console.log("  ‚Ä¢ H·ªó tr·ª£ th√¥ng tin mua s·∫Øm");
        console.log("  ‚Ä¢ Gi·∫£i ƒë√°p c√°c c√¢u h·ªèi v·ªÅ d·ªãch v·ª•");
        console.log("\nG√µ 'exit' ho·∫∑c 'quit' ƒë·ªÉ k·∫øt th√∫c.");
        console.log("G√µ 'models' ƒë·ªÉ xem g·ª£i √Ω models kh√°c.");
        console.log("-".repeat(60));
        console.log(`ü§ñ S·ª≠ d·ª•ng model: ${MODEL_NAME} (qua OpenRouter)`);
        console.log(`üß† Thinking traces: ${DISABLE_THINKING ? 'DISABLED' : 'ENABLED'}`);

        // Check if using free model and warn about limitations
        if (MODEL_NAME.includes(':free')) {
            console.log("üí∞ Model mi·ªÖn ph√≠: Tool calling c√≥ th·ªÉ b·ªã h·∫°n ch·∫ø, s·ª≠ d·ª•ng ch·∫ø ƒë·ªô fallback");
        }

        console.log("-".repeat(60));

        while (true) {
            try {
                const query = await this.rl.question("\nüí¨ C√¢u h·ªèi c·ªßa b·∫°n: ");

                if (query.toLowerCase().trim() === 'exit' ||
                    query.toLowerCase().trim() === 'quit' ||
                    query.toLowerCase().trim() === 'q') {
                    console.log("\nüëã C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng d·ªãch v·ª• Aliconcon. H·∫πn g·∫∑p l·∫°i!");
                    break;
                }

                if (query.toLowerCase().trim() === 'models') {
                    this.showModelSuggestions();
                    continue;
                }

                if (query.trim()) {
                    console.log("üîç ƒêang x·ª≠ l√Ω c√¢u h·ªèi...");
                    try {
                        const response = await this.processQuery(query);
                        console.log(`\nü§ñ Tr·ª£ l√Ω Aliconcon:\n${response}`);
                    } catch (error) {
                        console.log(`‚ùå L·ªói: ${error}`);
                        console.log("üí° Th·ª≠ g√µ 'models' ƒë·ªÉ xem g·ª£i √Ω models kh√°c");
                    }
                }
            } catch (error) {
                console.log(`‚ùå L·ªói: ${error}`);
                break;
            }
        }
    }

    showModelSuggestions() {
        console.log("\nü§ñ G·ª¢I √ù MODELS CHO ALICONCON MCP:");
        console.log("-".repeat(50));

        console.log("\nüí∞ MODELS MI·ªÑN PH√ç H·ªñ TR·ª¢ TOOL CALLING:");
        console.log("export LLM_MODEL='qwen/qwen3-30b-a3b:free'");
        console.log("export LLM_MODEL='meta-llama/llama-4-maverick:free'");
        console.log("export LLM_MODEL='google/gemini-2.5-pro:free'");

        console.log("\nüÜì MODELS MI·ªÑN PH√ç (FALLBACK MODE):");
        console.log("export LLM_MODEL='deepseek/deepseek-r1:free'");
        console.log("export LLM_MODEL='mistral/mistral-small-3.1:free'");

        console.log("\nüíé MODELS C√ì PH√ç M·∫†NH:");
        console.log("export LLM_MODEL='openai/gpt-4o'");
        console.log("export LLM_MODEL='anthropic/claude-3.5-sonnet'");
        console.log("export LLM_MODEL='google/gemini-2.5-pro'");

        console.log("\nüí° ƒê·ªÉ thay ƒë·ªïi model:");
        console.log("1. Tho√°t ch∆∞∆°ng tr√¨nh (Ctrl+C)");
        console.log("2. Ch·∫°y l·ªánh export ·ªü tr√™n");
        console.log("3. Kh·ªüi ƒë·ªông l·∫°i: bun run index.ts");
        console.log("-".repeat(50));
    }

    async cleanup() {
        this.rl.close();
        logger.info("üîå Closing MCP client...");
    }
}

async function main() {
    // Check OpenRouter API key
    if (!OPENROUTER_API_KEY) {
        console.error("‚ùå OPENROUTER_API_KEY is not set!");
        console.log("üí° H∆∞·ªõng d·∫´n:");
        console.log("1. Truy c·∫≠p https://openrouter.ai v√† ƒëƒÉng k√Ω t√†i kho·∫£n MI·ªÑN PH√ç");
        console.log("2. L·∫•y API key t·ª´ dashboard");
        console.log("3. ƒê·∫∑t bi·∫øn m√¥i tr∆∞·ªùng: export OPENROUTER_API_KEY=your_api_key");
        process.exit(1);
    }

    const client = new AliconconMCPClient();

    try {
        // Connect to MCP server
        const connected = await client.connectToServer();
        if (!connected) {
            console.error("‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn MCP server");
            console.log("üí° ƒê·∫£m b·∫£o MCP server ƒëang ch·∫°y:");
            console.log("cd server-mcp && bun run server.ts");
            process.exit(1);
        }

        // Start chat loop
        await client.startChatLoop();

    } catch (error) {
        console.error("‚ùå L·ªói:", error);
    } finally {
        await client.cleanup();
    }
}

// Handle process termination
process.on('SIGINT', async () => {
    console.log("\nüëã ƒêang tho√°t...");
    process.exit(0);
});

process.on('SIGTERM', async () => {
    console.log("\nüëã ƒêang tho√°t...");
    process.exit(0);
});

// Run the application
if (import.meta.main) {
    main().catch(console.error);
}